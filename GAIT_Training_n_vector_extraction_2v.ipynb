{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmHzYDKI4kpO",
        "outputId": "e7a2c5c4-da17-4685-b272-4b577394329a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBNTeO565RF9",
        "outputId": "8fdd08ae-ac46-43c7-8b6c-cc468d347e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 56 dataset files.\n"
          ]
        }
      ],
      "source": [
        "import glob # Import the glob module\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Filtered Data\"  # Update this path\n",
        "\n",
        "# Get all text files inside 12 subfolders\n",
        "txt_files = glob.glob(os.path.join(dataset_path, \"**/*.txt\"), recursive=True)\n",
        "\n",
        "print(f\"Found {len(txt_files)} dataset files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkDSu2dC7e1r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your dataset folder in Google Drive\n",
        "base_path = \"/content/drive/MyDrive/Filtered Data\"\n",
        "\n",
        "# List to store file paths\n",
        "txt_files = []\n",
        "\n",
        "# Traverse the dataset folders\n",
        "for folder in sorted(os.listdir(base_path)):\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "\n",
        "    if os.path.isdir(folder_path):  # Ensure it's a folder\n",
        "        if folder == \"008\":  # Special handling for folder 8\n",
        "            for subfolder in [\"OFF_1\", \"OFF_2\"]:\n",
        "                subfolder_path = os.path.join(folder_path, subfolder)\n",
        "                if os.path.exists(subfolder_path):  # Check if subfolder exists\n",
        "                    for file in os.listdir(subfolder_path):\n",
        "                        if file.endswith(\".txt\"):\n",
        "                            txt_files.append(os.path.join(subfolder_path, file))\n",
        "        else:  # All other folders where .txt files are directly present\n",
        "            for file in os.listdir(folder_path):\n",
        "                if file.endswith(\".txt\"):\n",
        "                    txt_files.append(os.path.join(folder_path, file))\n",
        "\n",
        "# Verify collected files\n",
        "print(f\"Total .txt files found: {len(txt_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3n_g185DpKv",
        "outputId": "f9dee868-fc08-4bbf-8f64-0381f3320fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total .txt files found: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYeRBZ627aR3",
        "outputId": "e14067b5-eeac-4674-9f0a-419f71c5dade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gait Data Shape: (6211056, 28)\n"
          ]
        }
      ],
      "source": [
        "# Columns related to acceleration & gyroscope (32-59)\n",
        "gait_columns = list(range(32, 59))  # Includes x, y, z accelerometer + gyro\n",
        "label_column = [60]  # Freezing of Gait (FoG) Label\n",
        "\n",
        "# Initialize list for storing processed data\n",
        "all_data = []\n",
        "\n",
        "# Read all files\n",
        "for file in txt_files:\n",
        "    df = pd.read_csv(file, header=None)  # No header in dataset\n",
        "    gait_data = df[gait_columns + label_column]  # Extract only gait & labels\n",
        "    all_data.append(gait_data)\n",
        "\n",
        "# Merge all files\n",
        "gait_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Gait Data Shape:\", gait_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ensure GPU usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Convert gait data to PyTorch tensor and move to GPU\n",
        "gait_tensor = torch.tensor(gait_df.values, dtype=torch.float32, device=device)\n",
        "\n",
        "window_size = 1000  # 2 sec (500Hz)\n",
        "step_size = 500     # 50% overlap\n",
        "\n",
        "# Batch-wise segmentation for speed\n",
        "num_samples = (gait_tensor.shape[0] - window_size) // step_size\n",
        "\n",
        "# Preallocate tensors\n",
        "X = torch.zeros((num_samples, window_size, gait_tensor.shape[1] - 1), device=device)\n",
        "y = torch.zeros((num_samples,), dtype=torch.long, device=device)\n",
        "\n",
        "# Fill tensors\n",
        "for i in range(num_samples):\n",
        "    start = i * step_size\n",
        "    X[i] = gait_tensor[start : start + window_size, :-1]  # All gait features\n",
        "    y[i] = gait_tensor[start + window_size - 1, -1]  # Last label in window\n",
        "\n",
        "print(\"Segmented Data Shape:\", X.shape, \"Labels Shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVQh67OJXXtd",
        "outputId": "ea6f9888-6578-45b9-8e4b-cd61a22f69a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmented Data Shape: torch.Size([12420, 1000, 27]) Labels Shape: torch.Size([12420])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Move data to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Convert DataFrame to NumPy\n",
        "gait_data = gait_df.iloc[:, :-1].values  # Features\n",
        "labels = gait_df.iloc[:, -1].values  # Labels\n",
        "\n",
        "# Convert to PyTorch tensors and move to GPU\n",
        "gait_tensor = torch.tensor(gait_data, dtype=torch.float32, device=device)\n",
        "labels_tensor = torch.tensor(labels, dtype=torch.int64, device=device)\n",
        "\n",
        "# Segmentation parameters\n",
        "window_size = 1000  # 2 seconds\n",
        "step_size = 500\n",
        "\n",
        "segments = []\n",
        "labels = []\n",
        "\n",
        "# GPU batch segmentation\n",
        "for i in range(0, len(gait_tensor) - window_size, step_size):\n",
        "    segment = gait_tensor[i:i+window_size]  # Feature segment\n",
        "    label = labels_tensor[i+window_size-1]  # Label at window end\n",
        "    segments.append(segment)\n",
        "    labels.append(label)\n",
        "\n",
        "# Stack as tensors\n",
        "X = torch.stack(segments).to(device)\n",
        "y = torch.tensor(labels, dtype=torch.int64, device=device)\n",
        "\n",
        "print(\"Segmented Data Shape:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHWUfZGnYFT0",
        "outputId": "c7b0ca65-c66e-4969-ffbf-222287499474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmented Data Shape: torch.Size([12421, 1000, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "USING CNN_LSTM"
      ],
      "metadata": {
        "id": "jZdJ_pY4meg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "\n",
        "        # CNN Layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        # LSTM Layers\n",
        "        self.lstm = nn.LSTM(input_size=64, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Fully connected output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # Convert to (batch, channels, time) for CNN\n",
        "        x = self.pool(self.relu(self.conv1(x)))  # CNN Feature Extraction\n",
        "        x = x.permute(0, 2, 1)  # Back to (batch, time, features)\n",
        "\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_features = lstm_out[:, -1, :]  # Extract last LSTM hidden state\n",
        "\n",
        "        output = self.fc(lstm_features)  # Final classification output\n",
        "        return output\n",
        "\n",
        "    # New method to extract feature vectors\n",
        "    def extract_features(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_features = lstm_out[:, -1, :]  # Extract feature vector before final FC layer\n",
        "        return lstm_features\n"
      ],
      "metadata": {
        "id": "_sru3F6-Y7m4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define model parameters\n",
        "input_size = 27  # Number of gait features\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "output_size = 1  # Binary classification (FoG or no FoG)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN_LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "# Define Loss and Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X).squeeze()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "print(\"CNN-LSTM Training Completed ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXa7aUEYZOhP",
        "outputId": "255f1b2c-a3ba-4d18-b92f-d76bfa6026df"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.575844870790408\n",
            "Epoch 2, Loss: 0.5622298310232315\n",
            "Epoch 3, Loss: 0.5670619021466308\n",
            "Epoch 4, Loss: 0.5626194989757906\n",
            "Epoch 5, Loss: 0.5573569317722628\n",
            "CNN-LSTM Training Completed ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        outputs = model(batch_X).squeeze()\n",
        "        preds = torch.round(torch.sigmoid(outputs))  # Convert logits to binary predictions\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}% ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1w5PP4dZvlX",
        "outputId": "c1ea8324-d65f-42af-9259-4f0d00a8b19f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 77.79% ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "feature_vectors = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, _ in test_loader:  # No need for labels here\n",
        "        batch_X = batch_X.to(device)\n",
        "        features = model.extract_features(batch_X)  # Extract features from LSTM layer\n",
        "        feature_vectors.append(features.cpu().numpy())\n",
        "\n",
        "# Convert to numpy array\n",
        "feature_vectors = np.vstack(feature_vectors)\n",
        "\n",
        "# Save feature vectors to a file\n",
        "np.save('gait_feature_vectors.npy', feature_vectors)\n",
        "print(\"Feature vectors saved successfully! ✅\")\n"
      ],
      "metadata": {
        "id": "5Ds6HiLObENV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32eaf2c5-1743-4e69-aa4f-2ba6a7a25407"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature vectors saved successfully! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('gait_feature_vectors.npy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XBRh7ATreksD",
        "outputId": "0eb2ceba-5581-4f2a-dd74-8aa8601d406f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b3b91fe3-888a-4aa7-b8a7-d87c9a05bdd9\", \"gait_feature_vectors.npy\", 1272448)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_vectors.shape)  # Should be (num_samples, feature_dim)\n",
        "print(\"Example feature vector:\", feature_vectors[0][:10])  # Print first 10 values of first vector\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBAf8HASjMee",
        "outputId": "32444d38-da39-4887-81ae-59a7c24dc773"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2485, 128)\n",
            "Example feature vector: [-0.03943942 -0.2911995   0.2068045  -0.04807587  0.02643567  0.2355742\n",
            "  0.0088343   0.03526265 -0.00297631  0.07361782]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "USING RANDOM FOREST"
      ],
      "metadata": {
        "id": "QCKmV8OvmE6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib"
      ],
      "metadata": {
        "id": "woqbcnrXmw_R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load the segmented data (assuming it's already in `X` and `y`)\n",
        "print(\"Segmented Data Shape:\", X.shape)  # Should be (num_samples, window_size, features)\n",
        "\n",
        "# ✅ Flatten the time-series data for Random Forest (convert 3D to 2D)\n",
        "X_flat = X.reshape(X.shape[0], -1)  # Flatten time steps into features\n",
        "print(\"Flattened Data Shape for RF:\", X_flat.shape)  # (samples, window_size * features)\n",
        "\n",
        "# ✅ Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Initialize Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "print(\"Training Random Forest...\")\n",
        "\n",
        "# ✅ Convert PyTorch tensors to NumPy\n",
        "X_train = X_train.cpu().numpy()\n",
        "X_test = X_test.cpu().numpy()\n",
        "y_train = y_train.cpu().numpy()\n",
        "y_test = y_test.cpu().numpy()\n",
        "\n",
        "\n",
        "# ✅ Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"🎯 Random Forest Training Completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLxaHlYfm4qq",
        "outputId": "fd50094e-a317-4c8a-c868-669223dc2420"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmented Data Shape: torch.Size([12421, 1000, 27])\n",
            "Flattened Data Shape for RF: torch.Size([12421, 27000])\n",
            "Training Random Forest...\n",
            "🎯 Random Forest Training Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Test accuracy\n",
        "y_pred = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"✅ Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ✅ Classification Report\n",
        "print(\"\\n🔹 Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XeBV08mnDju",
        "outputId": "a94cfbce-868d-49fc-e8c8-d217a4c06891"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test Accuracy: 0.8829\n",
            "\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.91      0.90      1433\n",
            "         1.0       0.88      0.84      0.86      1052\n",
            "\n",
            "    accuracy                           0.88      2485\n",
            "   macro avg       0.88      0.88      0.88      2485\n",
            "weighted avg       0.88      0.88      0.88      2485\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Extract feature vector using RF’s internal feature representation\n",
        "feature_vectors = rf_model.apply(X_test)  # RF outputs leaf indices as features\n",
        "\n",
        "# ✅ Save feature vector as .npy for multimodal integration\n",
        "feature_vectors_path = \"/content/drive/MyDrive/gait_feature_vectors_rf.npy\"\n",
        "np.save(feature_vectors_path, feature_vectors)\n",
        "print(f\"✅ Feature vectors saved at: {feature_vectors_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QPrZJ_n4LZ",
        "outputId": "6098d5f5-2a57-4542-af4e-c6d6b68f559d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature vectors saved at: /content/drive/MyDrive/gait_feature_vectors_rf.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"/content/drive/MyDrive/gait_feature_vectors_rf.npy\")  # Directly download the file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KthI9dSaovpe",
        "outputId": "79f2d32d-0676-4179-f020-f1d875445e18"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d41b383c-dc41-4248-b24e-890b0a17c5ca\", \"gait_feature_vectors_rf.npy\", 1988128)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the file\n",
        "feature_vectors = np.load(\"/content/drive/MyDrive/gait_feature_vectors_rf.npy\")\n",
        "\n",
        "# Check shape\n",
        "print(\"Feature Vector Shape:\", feature_vectors.shape)\n",
        "\n",
        "# Preview first few rows\n",
        "print(\"First 5 rows:\\n\", feature_vectors[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Poit-e2pqrV",
        "outputId": "2aae17ca-aa5c-4989-ea05-7c30d23593ba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Vector Shape: (2485, 100)\n",
            "First 5 rows:\n",
            " [[  38  985 1108  973 1014  921  959 1103  980  970  816  685  948 1068\n",
            "   996  989  480 1039  970  982 1046 1016 1087  860  916 1034 1154 1088\n",
            "  1110 1023 1062  757 1095  974 1003  998  708 1072  959 1084 1104 1089\n",
            "  1099 1141 1029 1011 1091 1061  974 1019  947  956  485  781 1119  702\n",
            "   917  754 1034 1065  960  971  356  669  882 1139  474 1112 1029 1018\n",
            "   992  996 1030 1005  993  830  941 1046 1088   79  752 1148 1127 1088\n",
            "   107  260 1035 1121 1031 1017  619  861 1053  867 1065   27   61 1063\n",
            "   999  977]\n",
            " [1007 1070 1077  927  944  890  875 1020  850  939  554  569  882 1037\n",
            "   873  905 1142 1015  931  920  936  868  916  518 1050  863 1032 1012\n",
            "   993  935 1028  500 1009 1055  951  947  809 1000  839  934 1008 1036\n",
            "  1008 1053  885  845 1031  546  872  940  871  873 1076  845  987  525\n",
            "   578 1107  938  865  893  932 1116 1081  567 1072  183 1046  862  872\n",
            "   877  876  943  959  891  250  878  871  907 1132 1102 1068 1061 1003\n",
            "  1152 1104  935  993  945  570  562  567  885  537  950  938  948 1055\n",
            "   925  925]\n",
            " [ 320  573  441  700  581  430  706  596  201  565  275  372  223  436\n",
            "   461  258  391  376  601  754  408  352  703   76  585  459  435  195\n",
            "   675  285  475  106  872  351  688  182  255  473  213  760  411  525\n",
            "   381  651  632  220  288  147  646  407  512  536  142  152  308   71\n",
            "   298  277  568  156  629  118  252  218  160  836   62  799  188  408\n",
            "   252  134  323  205  200  351  582  176  171  130  385  780  508  398\n",
            "   220  278  625  252  827  128  150  218  343  288  461  500  336  644\n",
            "   726  598]\n",
            " [  73  137  276 1082 1103 1115 1070   79 1044 1114  655  683 1048  121\n",
            "  1076 1108  617   18  109 1083 1133 1078 1112  667   73 1048  214   49\n",
            "   305   59  132  874  213   69 1097 1106  876  266  927   74   86  152\n",
            "   222  151 1041 1070  122  648 1092 1085 1085 1071  586 1053  125  820\n",
            "   711   74 1140 1079 1117 1077   96  129  675  266  370   84 1039 1080\n",
            "  1084  954 1133  140 1110  950 1059 1089 1008  698  114  193  138  135\n",
            "   107   27  119  131 1132  791  775  679 1082  769  121   86  107  226\n",
            "  1047 1085]\n",
            " [ 607  113   94  759  690  613  609  244  545  680  454  341  554  644\n",
            "   748  651  366  768  643  705  817  741  607  455  569  453  190  349\n",
            "   372  863  502  299  919  350  771  687  618  811  568  485  744  693\n",
            "   332  673  548  618  785  438  568  738  595  637  448  717  556  439\n",
            "   398  607  726  488  409  668  695  437  466  726  686  598  619  524\n",
            "   745  515  551  510  632  657  677  646  790  523  521  815  576  570\n",
            "   614  578  654  818  664  443  442  443  339  271  606  735  820  130\n",
            "   664  459]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Test Data Shape:\", X_test.shape)  # Check before feature extraction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVKIhcwHp4Z2",
        "outputId": "15f1a3f5-9856-482a-8a32-b02cc41ebcf1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Test Data Shape: (2485, 27000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Any empty feature vectors?\", np.all(feature_vectors == 0, axis=1).sum())  # Should be 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YkQK5oZqKAQ",
        "outputId": "a945c7d1-dad3-4983-bfc6-ab6f84c7c4a7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any empty feature vectors? 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}